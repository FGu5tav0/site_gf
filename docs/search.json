[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Gustavo Frosi",
    "section": "",
    "text": "Github\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     Email\n  \n  \n     CV.Lattes\n  \n  \n     ResearchGate\n  \n\n\n\nOlá! Sou Gustavo Frosi, formado em engenharia agronômica e mestre em ciência do solo. Atualmente, estou cursando doutorado na mesma área, concentrando minhas pesquisas e interesses de estudo na química e mineralogia do solo. Durante meu mestrado, investigamos o impacto da aplicação de resíduo industrial nos parâmetros químicos e mineralógicos do solo. No doutorado, meu foco é estabelecer a relação entre a mineralogia do solo como componente fundamental para a adubação de potássio e a capacidade de prever, por meio da mineralogia, o comportamento do nutriente e sua dinâmica no solo.\nAo longo da minha trajetória acadêmica, estabeleci um contato constante com dados e análises estatísticas, o que, ao longo dos anos, conduziu ao desenvolvimento de um verdadeiro interesse por essa área. Inegavelmente, ciência e dados caminham lado a lado.\n\nA estatística é a gramática da ciência - Karl Pearson\n\nEsta frase de Pearson descreve bem meu apego e dedicação ao estudo da análise de dados e estatística, motivando-me a avançar nos estudos nessa área.\n\nInteresses\n\n\n\n\n\nCiência do Solo\nAnálise de dados\n\n\n\n\nMineralogia\nManipulação\n\n\nQuímica\nInferência\n\n\nFertilidade\nVisualização\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHabilidades\n     R\n     Markdown/Quarto\n     Visualização/Manipulação de dados\n     Inferência\n     Python\n\n\nEducação\n Atualmente, doutorando em ciência do solo pela Universidade Federal do Rio Grande do Sul  (2022 - ).\n Mestre em ciência do solo pela Universidade Federal do Rio Grande do Sul (UFRGS) (2020 - 2022).\n Engenheiro agrônomo pelo Instituto Federal do Paraná  (2015 - 2019)."
  },
  {
    "objectID": "recap.html",
    "href": "recap.html",
    "title": "Gustavo Frosi",
    "section": "",
    "text": "Web scraping Nota Fiscal Gaúcha\n\n\n\nR\n\n\npython\n\n\nWeb scraping\n\n\n\nAutomatizando o download de notas para consumidor final e a extração de dados.\n\n\n\nGustavo Frosi\n\n\n5 de jan. de 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrabalhos - XXIII CLACS | XXXVIII CBCS\n\n\n\nR\n\n\nSolos\n\n\n\nExplorando a relação dos trabalhos publicados e apresentados no XXIII CLACS | XXXVIII CBCS.\n\n\n\nGustavo Frosi, Dayana Eckert\n\n\n17 de dez. de 2023\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "Projetos/index.html",
    "href": "Projetos/index.html",
    "title": "Gustavo Frosi",
    "section": "",
    "text": "Em construção…"
  },
  {
    "objectID": "CV/index.html",
    "href": "CV/index.html",
    "title": "Gustavo Frosi",
    "section": "",
    "text": "Página em construção"
  },
  {
    "objectID": "recap/2023-12-17 CBCS 2023/index.html",
    "href": "recap/2023-12-17 CBCS 2023/index.html",
    "title": "Trabalhos - XXIII CLACS | XXXVIII CBCS",
    "section": "",
    "text": "O Congresso Brasileiro de Ciência do Solo (CBCS) é um evento técnico-científico que ocorre a cada dois anos (anos ímpares). O objetivo deste evento é reunir alunos, professores, pesquisadores e profissionais das áreas afins para a troca de conhecimento e discussão sobre as futuras perspectivas da ciência do solo.\nEsse ano o XXXVIII CBCS ocorreu em Florianopolis – SC, concomitante a ele ocorreu o XXIII Congresso Latino-Americado de Ciência do solo (CLACS). O evento em conjunto foi chamado de SOLOS FLORIPA 2023, com organização das sociedades Latino-americana (SLCS) e Brasileira (SBCS) da Ciência do Solo e realização da Empresa de Pesquisa Agropecuária e Extensão Rural de Santa Catarina (Epagri).\nUma das características mais importante do congresso é a possibilidade de os “pesquisadores” apresentarem trabalhos técnico-científicos sobre seus respectivos objetos de estudo. Diante disso, surge a dúvida em saber quais as áreas/subáreas teve as maiores quantidades de trabalhos apresentados e talvez entender o foco das pesquisas em Ciência do Solo na atualidade. Para sanar essa dúvida (pelo menos parcialmente) apresento nesse post uma forma de retirar os dados do site do congresso e realizar uma apresentação gráfica sobre os trabalhos. Para isso utilizo a linguagem de programação R.\nPara mais informações acesse o site: https://solosfloripa2023.com.br/solos2023"
  },
  {
    "objectID": "recap/2023-12-17 CBCS 2023/index.html#dados",
    "href": "recap/2023-12-17 CBCS 2023/index.html#dados",
    "title": "Trabalhos - XXIII CLACS | XXXVIII CBCS",
    "section": "Dados",
    "text": "Dados\nOs dados do número de trabalhos está na página de Trabalho Aprovados no site. A captura dos dados foi realizada com o endereço eletrônico da página. Um avaliação prévia de como se conportava a página e como os dados aparaciam foi realizada.\n\n\nCódigo\nprimeira_parte &lt;- \"https://solosfloripa2023.com.br/evento/solos2023/trabalhosaprovados?titulo=&autor=&t1area_id=\"\n\nid &lt;- c(1, 2, 3, 8, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16)\n\nsegunda_parte &lt;- \"&modeloformaapresentacaofinal_id=&btBuscar=Buscar\"\n\n\nUm loop foi realizado para remover os dados de cada uma das áreas e subareas.\n\n\nCódigo\ndf &lt;- as.data.frame(x = 1:length(id))\nfor (i in 1:16) {\n  dados &lt;- httr::GET(paste0(primeira_parte, id[i], segunda_parte))\n  get_content &lt;- httr::content(dados)\n\n  raw_table &lt;- get_content |&gt;\n    rvest::html_nodes(\".container-fluid\")\n\n  df[i, ] &lt;-\n    raw_table[[3]] |&gt;\n    rvest::html_text() |&gt;\n    strsplit(\"\\n\") |&gt;\n    unlist() |&gt;\n    enframe(name = NULL, value = \"linha\") |&gt;\n    dplyr::filter(stringr::str_detect(linha, pattern = \".*registro\"))\n}\n\n\nAlém de captar as iformações, foi realizado um processamento e manipulação para organizar os dados.\n\n\nCódigo\ndivi &lt;- raw_table[[3]] |&gt;\n  rvest::html_text() |&gt;\n  strsplit(\"\\n\") |&gt;\n  unlist() |&gt;\n  enframe(name = NULL, value = \"linha\") |&gt;\n  dplyr::filter(stringr::str_detect(linha, pattern = \" TODASDivisã\")) |&gt;\n  str_split(pattern = \"Di\", simplify = T) |&gt;\n  as.data.frame() |&gt;\n  pivot_longer(cols = 2:17, names_to = \"Divi\", values_to = \"nome\") |&gt;\n  filter(Divi != \"V1\") |&gt;\n  mutate(di = \"Di\") |&gt;\n  transmute(Divi = paste(di, nome, sep = \"\"))\n\n\nd_final &lt;- cbind(divi, df)\n\ndados.ok &lt;- d_final |&gt;\n  mutate(\n    partici = str_extract(`1:length(id)`,\n      pattern = \"[:digit:]{1,}\"\n    ),\n    partici = as.numeric(partici)\n  ) \n\n\ncomi &lt;- str_split(d_final$Divi, \":\")\ndata_separado &lt;- data.frame(do.call(rbind, comi))\n\ndf_ok &lt;- cbind(data_separado, dados.ok)\n\ndf_ok &lt;- df_ok |&gt; mutate(remover = str_sub(df_ok$X2, start = 16, end = 90))\n\nfont_add(\"Didot\", \"GFS_Didot/GFSDidot-Regular.ttf\")\n\nshowtext_auto()"
  },
  {
    "objectID": "recap/2023-12-17 CBCS 2023/index.html#trabalhos-dentro-de-cada-divisão",
    "href": "recap/2023-12-17 CBCS 2023/index.html#trabalhos-dentro-de-cada-divisão",
    "title": "Trabalhos - XXIII CLACS | XXXVIII CBCS",
    "section": "Trabalhos dentro de cada divisão",
    "text": "Trabalhos dentro de cada divisão\n\nDivisão 1Divisão 2Divisão 3Divisão 4\n\n\n\n\nCódigo\ndf_ok |&gt;\n  filter(X1 == \"Divisão 1 – Solo no espaço e no tempo\") |&gt;\n  ggplot(aes(y = partici, x = fct_reorder(remover, partici))) +\n  coord_flip() +\n  geom_col(fill = \"#ef8118\", col = \"#bc6a1d\") +\n  # facet_wrap(~X1, scales = \"free\") +\n  labs(\n    x = NULL, y = \"Nº de trabalhos\",\n    title = 'Resumos no &lt;span style = \"color:#ef8118\"&gt; XXIII CLACS | XXXVIII CBCS &lt;/span&gt;',\n    subtitle = \"Divisão 1 – Solo no espaço e no tempo\"\n  ) +\n  geom_text(aes(label = partici), nudge_y = -2, col = \"black\", size = 5) +\n  theme_minimal(24) +\n  theme(\n    text = element_text(family = \"Didot\"),\n    plot.title = ggtext::element_markdown()\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCódigo\ndf_ok |&gt;\n  filter(X1 == \"Divisão 2 – Processos e Propriedades do Solo\") |&gt;\n  ggplot(aes(y = partici, x = fct_reorder(remover, partici))) +\n  coord_flip() +\n  geom_col(fill = \"#ef8118\", col = \"#bc6a1d\") +\n  # facet_wrap(~X1, scales = \"free\") +\n  labs(\n    x = NULL, y = \"Nº de trabalhos\",\n    title = 'Resumos no &lt;span style = \"color:#ef8118\"&gt; XXIII CLACS | XXXVIII CBCS &lt;/span&gt;',\n    subtitle = \"Divisão 2 – Processos e Propriedades do Solo\"\n  ) +\n  geom_text(aes(label = partici), nudge_y = -4, col = \"black\", size = 6) +\n  theme_minimal(24) +\n  theme(\n    text = element_text(family = \"Didot\"),\n     plot.title  = element_markdown()\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCódigo\ndf_ok |&gt;\n  filter(X1 == \"Divisão 3 – Uso e Manejo do Solo\") |&gt; \nmutate(remover = factor(remover, levels = c(\n  \" Fertilidade do Solo e Nutrição de Plantas\",\n  \" Corretivos e Fertilizantes\", \n  \" Manejo e Conservação do Solo e da Água\", \n  \" Planejamento do Uso da Terra\", \n  \" Poluição, Remediação do Solo e Recuperação de Áreas Degradadas\"\n), labels = c(\n  \"Fertilidade do Solo e \\n Nutrição de Plantas\",\n  \"Corretivos e Fertilizantes\",\n  \"Manejo e Conservação \\n do Solo e da Água\",\n  \"Planejamento do Uso da Terra\",\n  \"Poluição, Remediação do Solo e \\n Recuperação de Áreas Degradadas\"\n))) |&gt;\n  ggplot(aes(y = partici, x = fct_reorder(remover, partici))) +\n  coord_flip() +\n  geom_col(fill = \"#ef8118\", col = \"#bc6a1d\") +\n  # facet_wrap(~X1, scales = \"free\") +\n  labs(\n    x = NULL, y = \"Nº de trabalhos\",\n    title = 'Resumos no &lt;span style = \"color:#ef8118\"&gt; XXIII CLACS | XXXVIII CBCS &lt;/span&gt;',\n    subtitle = \"Divisão 3 – Uso e Manejo do Solo\"\n  ) +\n  geom_text(aes(label = partici), nudge_y = -13, col = \"black\", size = 6) +\n  theme_minimal(24) +\n  theme(\n    text = element_text(family = \"Didot\"),\n    plot.title = element_markdown()\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCódigo\ndf_ok |&gt;\n  filter(X1 == \"Divisão 4 - Solo, Ambiente e Sociedade\") |&gt;\n  mutate(remover = factor(remover, labels = c(\n    \"Educação em Solos e \\n Percepção Pública do Solo\",\n    \"História, Epistemologia e \\n Sociologia da Ciência\",\n    \"Solos e Segurança Alimentar\"\n  ))) |&gt;\n  ggplot(aes(y = partici, x = fct_reorder(remover, partici))) +\n  coord_flip() +\n  geom_col(fill = \"#ef8118\", col = \"#bc6a1d\") +\n  # facet_wrap(~X1, scales = \"free\") +\n  labs(\n    x = NULL, y = \"Nº de trabalhos\",\n    title = 'Resumos no &lt;span style = \"color:#ef8118\"&gt; XXIII CLACS | XXXVIII CBCS &lt;/span&gt;',\n    subtitle = \"Divisão 4 - Solo, Ambiente e Sociedade\"\n  ) +\n  geom_text(aes(label = partici), nudge_y = -2, col = \"black\", size = 6) +\n  theme_minimal(24) +\n  theme(\n    text = element_text(family = \"Didot\"),\n     plot.title  = element_markdown()\n  )"
  },
  {
    "objectID": "recap/2023-12-17 CBCS 2023/index.html#trabalhos-entre-as-divisões",
    "href": "recap/2023-12-17 CBCS 2023/index.html#trabalhos-entre-as-divisões",
    "title": "Trabalhos - XXIII CLACS | XXXVIII CBCS",
    "section": "Trabalhos entre as divisões",
    "text": "Trabalhos entre as divisões\nDe forma geral, observa-se que a maioria dos trabalhos submetidos e apresentados no evento pertence à divisão científica 3 – Uso e Manejo do Solo, totalizando 829 trabalhos. Em contrapartida, a divisão 4 – Solo, Ambiente e Sociedade apresentou o menor número de trabalhos, com apenas 58.\nNão podemos afirmar que esses números representam a totalidade dos trabalhos realizados em cada área, mas eles podem fornecer uma amostra do cenário atual das pesquisas em Ciência do Solo.\nA disparidade nos estudos entre as áreas da Ciência do Solo levanta questionamentos sobre a direção da pesquisa nesse campo. É pertinente refletir se nossas investigações estão se aproximando das necessidades da sociedade e se estão verdadeiramente cumprindo o papel que a Ciência deve desempenhar.\nEssa discrepância nos números sugere a importância de uma análise mais aprofundada sobre os temas predominantes e as lacunas existentes na pesquisa em Ciência do Solo. Incentivar a discussão dentro da comunidade científica pode ser valioso para garantir que as pesquisas estejam alinhadas com as demandas sociais e ambientais atuais.\n\n\nCódigo\ndf_ok |&gt;\n  group_by(X1) |&gt;\n  summarise(soma = sum(partici)) |&gt;\n  mutate(\n    X1 = factor(X1, labels = c(\n      \"Divisão 1 – Solo no \\n espaço e no tempo\",\n      \"Divisão 2 – Processos e \\n  Propriedades do Solo\",\n      \"Divisão 3 – Uso e \\n Manejo do Solo\",\n      \"Divisão 4 - Solo, \\n Ambiente e Sociedade\"\n    )),\n    total = sum(soma)\n  ) |&gt;\n  ggplot(aes(y = soma, x = fct_reorder(X1, soma))) +\n  coord_flip() +\n  geom_col(fill = \"#ef8118\", col = \"#bc6a1d\") +\n  # facet_wrap(~X1, scales = \"free\") +\n  labs(\n    x = NULL, y = \"Nº de trabalhos\",\n    title = 'Resumos no &lt;span style = \"color:#ef8118\"&gt; XXIII CLACS | XXXVIII CBCS &lt;/span&gt;',\n    subtitle = \"Total por divisão\"\n  ) +\n  geom_text(aes(label = soma), nudge_y = -32, col = \"black\", size = 6) +\n  theme_minimal(24) +\n  theme(\n    text = element_text(family = \"Didot\"),\n    plot.title = element_markdown()\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nOs códigos apresentados foram produzidos sem critérios de qualidade. Melhorias ainda podem ser feitas."
  },
  {
    "objectID": "recap/2024-02-05 webscraping python/index.html",
    "href": "recap/2024-02-05 webscraping python/index.html",
    "title": "Web scraping Nota Fiscal Gaúcha",
    "section": "",
    "text": "Você já se perguntou quanto gastou no mercado? E quais os itens que mais comprou? Bom, se você disse que não, acho melhor começar a pensar, e se você disse que sim, mas não sabe como fazer para buscar esses dados, eu tenho uma boa notícia!\nNeste texto, descrevo como utilizei o Python na criação de um código que automatizou o download das minhas notas fiscais pessoais (NFC: Nota Fiscal de Consumidor). Deixo claro que o código é destinado ao uso pessoal e doméstico. Minha intenção é apenas o controle de gastos financeiros (e outras brincadeiras com dados).\nO exemplo que utilizo aqui é para o site Nota Fiscal Gaúcha e serve apenas para quem utiliza o “benefício”. Fica obvio que é necessário colocar o CPF em todas as compras né.\nAntes de começar a codificar, é necessário baixar o webdriver, uma ferramenta para testes de automação que oferece uma série de recursos para utilizar o navegador. O webdriver a ser baixado depende do navegador que você utiliza e da versão instalada. No meu caso, vou ensinar com o navegador da Google, o Google Chrome na versão 121.0.6167.140.\nPara fazer o download do webdriver, basta acessar o link\nDepois de baixado, é necessário colar o webdriver na pasta onde está o executável do Python. No meu caso, como utilizo o Anaconda, colei no diretório do Anaconda, o mesmo onde fica o Python.\nAgora sim! Com isso, já é possível começar a escrever códigos."
  },
  {
    "objectID": "recap/2024-02-05 webscraping python/index.html#manipulação-de-banco-baixado",
    "href": "recap/2024-02-05 webscraping python/index.html#manipulação-de-banco-baixado",
    "title": "Web scraping Nota Fiscal Gaúcha",
    "section": "Manipulação de banco baixado",
    "text": "Manipulação de banco baixado\nDa planilha baixada do site, apenas a coluna que contém a chave de acesso da nota fiscal é relevante. Realizei uma pequena manipulação na planilha, removendo os espaços da coluna da chave de acesso, e a salvei como arquivo CSV.\n\n\nCódigo\nlibrary(tidyverse)\n\n\ndados &lt;- readxl::read_excel(\"notas/Nota Fiscal Gaúcha.xlsx\") |&gt;\n  janitor::clean_names() |&gt;\n  mutate(chave = chave_de_acesso |&gt; str_remove_all(pattern = \"\\\\s\")) |&gt;\n  select(chave)\n\n\n\nwrite.csv(x = dados, file = \"notas/para_auto.csv\")\n\n\n\n\n\n\n\n\nNota\n\n\n\nOs códigos apresentados foram produzidos sem critérios de qualidade. Melhorias ainda podem ser feitas."
  },
  {
    "objectID": "recap/2024-02-05 webscraping python/index.html#ajustando-a-planilha-com-a-chave-de-acesso",
    "href": "recap/2024-02-05 webscraping python/index.html#ajustando-a-planilha-com-a-chave-de-acesso",
    "title": "Web scraping Nota Fiscal Gaúcha",
    "section": "Ajustando a planilha com a chave de acesso",
    "text": "Ajustando a planilha com a chave de acesso\nDa planilha baixada do site, apenas a coluna que contém a chave de acesso da nota fiscal é relevante. Realizei uma pequena manipulação na planilha, removendo os espaços da coluna da chave de acesso, e a salvei como arquivo CSV.\n\nlibrary(tidyverse)\n\n\ndados &lt;- readxl::read_excel(\"Nota Fiscal Gaúcha.xlsx\") |&gt;\n  janitor::clean_names() |&gt;\n  mutate(chave = chave_de_acesso |&gt; str_remove_all(pattern = \"\\\\s\")) |&gt;\n  select(chave)\n\nwrite.csv(x = dados, file = \"notas/para_auto.csv\")\n\n\n\n\n\n\n\nNota\n\n\n\nOs códigos apresentados foram produzidos sem critérios de qualidade. Melhorias ainda podem ser feitas."
  },
  {
    "objectID": "recap/2024-02-05 webscraping python/index.html#ajuste-da-chave-de-acesso",
    "href": "recap/2024-02-05 webscraping python/index.html#ajuste-da-chave-de-acesso",
    "title": "Web scraping Nota Fiscal Gaúcha",
    "section": "Ajuste da chave de acesso",
    "text": "Ajuste da chave de acesso\nDa planilha baixada do site, apenas a coluna que contém a chave de acesso da nota fiscal é relevante. Realizei uma pequena manipulação na planilha, removendo os espaços da coluna da chave de acesso, e a salvei como arquivo CSV.\n\n\n\n\n\n\nNota\n\n\n\nCódigos em R\n\n\n\nlibrary(tidyverse)\n\ndados &lt;- readxl::read_excel(\"Nota Fiscal Gaúcha.xlsx\") |&gt;\n  janitor::clean_names() |&gt;\n  mutate(chave = chave_de_acesso |&gt; str_remove_all(pattern = \"\\\\s\")) |&gt;\n  select(chave)\n\nwrite.csv(x = dados, file = \"notas/para_auto.csv\")"
  },
  {
    "objectID": "recap/2024-02-05 webscraping python/index.html#encontrando-os-pontos-de-click",
    "href": "recap/2024-02-05 webscraping python/index.html#encontrando-os-pontos-de-click",
    "title": "Web scraping Nota Fiscal Gaúcha",
    "section": "Encontrando os pontos de click",
    "text": "Encontrando os pontos de click\n\n\n\n\n\n\nNota\n\n\n\nAgora serão apenas códigos em python\n\n\nO procedimento que apresento aqui é baseado em um algoritmo que controla o mouse do computador, realizando cliques e movimentos programados. Como é de se esperar, é necessário fornecer as coordenadas para guiar os movimentos. Essa é uma tarefa manual, porém, é realizada apenas uma vez e se aplica a todas as notas (baixei mais de 200 notas).\nUtilizei o MouseInfo para identificar os pontos. Após abrir o console do python (melhor fazer pelo console) é só dar os seguintes comandos:\n\nfrom mouseinfo import mouseInfo\n\nmouseInfo()\n\nBasta realizar um teste com o MouseInfo aberto. Abra o site onde as notas serão baixadas e identifique os pontos onde será necessário realizar os cliques.\n\n\n\n\n\n\nNota\n\n\n\nOs códigos apresentados foram produzidos sem critérios de qualidade. Melhorias ainda podem ser feitas."
  },
  {
    "objectID": "recap/2024-02-05 webscraping python/index.html#encontrando-os-pontos-de-clique",
    "href": "recap/2024-02-05 webscraping python/index.html#encontrando-os-pontos-de-clique",
    "title": "Web scraping Nota Fiscal Gaúcha",
    "section": "Encontrando os pontos de clique",
    "text": "Encontrando os pontos de clique\n\n\n\n\n\n\nNota\n\n\n\nAgora serão apenas códigos em python\n\n\nO procedimento que apresento aqui é baseado em um algoritmo que controla o mouse do computador, realizando cliques e movimentos programados. Como é de se esperar, é necessário fornecer as coordenadas para guiar os movimentos. Essa é uma tarefa manual, porém, é realizada apenas uma vez e se aplica a todas as notas (baixei mais de 200 notas).\nUtilizei o MouseInfo para identificar os pontos. Após abrir o console do python (melhor fazer pelo console) é só dar os seguintes comandos:\n\nfrom mouseinfo import mouseInfo\n\nmouseInfo()\n\nO vídeo abaixo demonstra o funcionamento do MouseInfo, exibindo as marcações das coordenadas x e y à medida que o mouse é movido.\nVideo\nPara encontar os ponto certo basta realizar um teste com o MouseInfo aberto. Abra o site onde as notas serão baixadas e identifique os pontos onde será necessário realizar os cliques. O atalho F6 pode ser utilizado no MouseInfo para marcar as pontos x e y. Siga os passo:\n1º Passo: Clique em avançar e depois em imprimir Figura 2\n\n\n\n\n\n\nFigura 2\n\n\n\n2º Passo: Clique em imprimir na parte do pdf Figura 3\n\n\n\n\n\n\nFigura 3\n\n\n\n3º Passo: Clique em salvar Figura 4\n\n\n\n\n\n\nFigura 4\n\n\n\nPor padrão, o Windows salva na pasta de downloads, mas é possível alterar para a pasta desejada. Basta encontrar o ponto de clique e realizar a mudança de destino."
  },
  {
    "objectID": "recap/2024-02-05 webscraping python/index.html#resultado",
    "href": "recap/2024-02-05 webscraping python/index.html#resultado",
    "title": "Web scraping Nota Fiscal Gaúcha",
    "section": "Resultado",
    "text": "Resultado\nO vídeo exibe o “robô” em ação, realizando a impressão e salvando automaticamente cada uma das notas. Na minha análise, as 205 notas que obtive foram processadas em quase 20 minutos, o que equivale a quase 1 minuto por nota (Um computador melhor fara em menos tempo). E você, ocupado com diversas tarefas, conseguiria realizar isso de maneira mais rápida? Mesmo ao atingir a nota de número 100 e perceber que ainda falta mais da metade. Se acha que não, a resposta para isso é simples: programação!\nVideo\nE agora, o que fazer com essas notas? Começar a extrair os dados manualmente? Pagar alguém para fazer? Excluir do computador e dar um ponto final?\nA resposta óbvia é sim, dar um ponto final e excluir. No entanto, se ainda assim você deseja extrair informações dos seus dados, eu aconselho a conferir um próximo post (no futuro), no qual explico o que fazer com as notas.\n\n\n\n\n\n\nNota\n\n\n\nOs códigos apresentados foram produzidos sem critérios de qualidade. Melhorias ainda podem ser feitas."
  }
]